# -*- coding: utf-8 -*-
"""Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FKA5bC6vML8cjkMjEE2lmo2FktpEytna

## Fetching data, training a classifier
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Add the project directory to the path
# %cd /content/drive/Shared drives/CS634/CS634Project/Q2
import os, sys
sys.path.append(os.getcwd())

import sklearn
import sklearn.ensemble
import sklearn.metrics
import pandas as pd
import numpy as np

"""**Data Processing**

We have used unprocessed tar file of Multi-Domain Sentiment Dataset and extracted the positive and negative review file.
Having converted the xml to csv, we obtained positive.csv and negative.csv.

We used following code to merge the two file to a single file named output.csv.


*file1 = open("positive.csv", "a")*

*file2 = open("negative.csv", "r")*

*for line in file2:*

   *file1.write(line)*

*file1.close()*

*file2.close()*

and renamed the file as output.csv

**Importing the processed data and Exploratory Data Analysis**
"""

# reading csv files
data1 = pd.read_csv('output.csv')

# Display first 5 records
data1.head()

# Display last 5 records
data1.tail()

#Displaying Unique classes of review_status
data1.review_status.unique()

#Checking for null values
data1.isnull().sum()

#review_text column is made to lower case
data1['review_text'] = data1['review_text'].str.lower()

#Assigning features as X and Label as y
X = data1['review_text']
y = data1['review_status']
print(X.shape)
print(y.shape)

#Importing for random.seed
import random
#Setting random seed, so values do not change for each execution.
random.seed(123)

"""**Splitting our dataset into train and test dataset**"""

#split our dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 125)
#test dataset size 20% , train dataset size 80%
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""**Let's use the Count vectorizer**"""

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(binary=True, stop_words='english')
vectorizer.fit(X_train)
train_vector = vectorizer.fit_transform(X_train)
test_vector = vectorizer.transform(X_test)

"""Now, let's say we want to use random forests for classification. It's usually hard to understand what random forests are doing, especially with many trees.

**Random Forest Classifier model for Sentiment Analysis**
"""

#Assigning rf as random forest classifier
rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500, random_state = 120)
#Fiiting the model
rf.fit(train_vector, y_train)

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
#predicting Label for test data
pred = rf.predict(test_vector)
print("Random Forest Accuracy Score : " , accuracy_score(y_test.values, pred))

sklearn.metrics.f1_score(y_test.values, pred, average='binary', pos_label= 'positive')

"""We see that this classifier achieves a good F1 score. 

Now Let's try XgBoost.

**XgBoost Classifier model for Sentiment Analysis**
"""

from xgboost import XGBClassifier
#Default hyperparameters
xgb_model = XGBClassifier()
xgb_model.fit(train_vector, y_train.values)

"""Key parameters in XGBoost(the ones which would affect model quality greatly),
 * max_depth - more complex classification task, deeper the tree (default is 3)
 * n_estimators — the number of runs XGBoost will try to learn (default is 100)
 * learning_rate — learning speed (default is 0.1)





When xgb_model.fit is executed with verbose=True(default), you will see each training run evaluation quality printed out.
"""

from xgboost import XGBClassifier
#Changing some hyperparameters
xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.1,  max_depth = 5)
xgb_model.fit(train_vector, y_train.values)

pred_xgb = xgb_model.predict(test_vector)
sklearn.metrics.f1_score(y_test.values, pred_xgb, average='binary', pos_label= 'positive')

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

print("Confusion Matrix:  \n" , confusion_matrix(y_test.values, pred_xgb))
print("\nRandom Forest Accuracy Score with XgBoost : ", accuracy_score(y_test.values, pred_xgb))
print("\nClassification Report: \n ",classification_report(y_test.values, pred_xgb))

"""# Explaining predictions using lime"""

# Commented out IPython magic to ensure Python compatibility.
#Installing Lime
# %pip install lime

#Importing Lime module
import lime

#Construct a Pipeline from the given estimators.
from sklearn.pipeline import make_pipeline
#making pipeline using vectorizer and rf - random forest classifier
c = make_pipeline(vectorizer, rf)

"""Lime explainers assume that classifiers act on raw text, but sklearn classifiers act on vectorized representation of texts. For this purpose, we use sklearn's pipeline, and implement ````predict_proba```` on raw_text lists."""

print(c.predict_proba([X_test.values[0]]))

#Assigning the class names as positive and negative
class_names = ['negative', 'positive']

"""Now we create an explainer object. We pass the ````class_names```` as an argument for prettier display."""

from lime.lime_text import LimeTextExplainer
explainer = LimeTextExplainer(class_names=class_names)

y_test.values[2]

"""We then generate an explanation with at most 6 features for an arbitrary document in the test set."""

idx = 2
exp1 = explainer.explain_instance(X_test.values[idx], c.predict_proba, num_features=6)
print('Document id: %d' % idx)
print('Probability(positive) =', c.predict_proba([X_test.values[idx]])[0, 1])
print('Probability(negative) =', c.predict_proba([X_test.values[idx]])[0, 0])
print('True class: %s' % y_test.values[idx])

"""The classifier got this example right (it predicted positive).  
The explanation is presented below as a list of weighted features. 
"""

exp1.as_list()

"""These weighted features are a linear model, which approximates the behaviour of the random forest classifier in the vicinity of the test example. Roughly, if we remove 'author' and 'poor' from the document , the prediction should move towards the opposite class (negative) by about the sum of the weights for both features. Let's see if this is the case."""

print('Original prediction:', rf.predict_proba(test_vector[idx])[0, 1])
tmp = test_vector[idx].copy()
tmp[0, vectorizer.vocabulary_['author']] = 0
tmp[0, vectorizer.vocabulary_['poor']] = 0
print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])
print('Difference:', rf.predict_proba(tmp)[0, 1] - rf.predict_proba(test_vector[idx])[0,1])

"""The words that explain the model around this document seem very arbitrary - not much to do with either positive or negative. In fact, these are words that appear in the reviews, which make distinguishing between the classes much easier."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig = exp1.as_pyplot_figure()

exp1.show_in_notebook(text=False)

"""Finally, we can also include a visualization of the original document, with the words in the explanations highlighted. Notice how the words that affect the classifier the most are all in the review."""

exp1.show_in_notebook(text=True)

"""**Summary**

As you can see in the above examples, LIME-The explainer helps the user understand what's happening behind the black-box model. With the given set of reviews (dataset), the Random Forest Classifier model was able to predict whether it is positive or negative review, and the LIME explained why. The LIME calculates the weight of the individual words locally in the given data based on the probability and classifies based on the terms that carried the highest weightage. It is evident that if the words with the highest weightage are removed, the prediction probability varies, making a difference to become the other class.

**Conclusion**

LIME is a useful tool that helps data scientists figure out why their predictive models fail and explain individual predictions. Moreover, it is easy to integrate with models built on common machine learning packages. Since LIME is model-agnostic, we will explore using it to interpret other models(Logistic Regression Classifier) in our Question 4.

This explainer works for any classifier you may want to use, as long as it implements ````predict_proba````
"""