# -*- coding: utf-8 -*-
"""Q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sh69PJ_Xx4A3OG5_DJiOnweq6zahpuQ1
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Add the project directory to the path
# %cd /content/drive/Shared drives/CS634/CS634Project/Q4
import os, sys
sys.path.append(os.getcwd())

# Install Lime
! pip install lime

#Importing the required packages
import lime
import sklearn
import sklearn.ensemble
import sklearn.metrics
import pandas as pd
import numpy as np

#Load Dataset
data = pd.read_csv("Youtube02-KatyPerry.csv")
data.head()

data.tail()

#data.isnull().sum()
data.info()

X = data['CONTENT']
y = data['CLASS']
print(X.shape)
print(y.shape)

X.head()

y.head()

#Importing for random.seed
import random
#Setting random seed, so values do not change for each execution.
random.seed(123)
#split our dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 123)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

#Displaying first five records
print(X_train.head())

#Displaying first five records
print(y_train.head())

"""**Vectorizer**"""

from sklearn.feature_extraction.text import TfidfVectorizer

vect = TfidfVectorizer(binary = True, stop_words='english')

X_train_dtm = vect.fit_transform(X_train)
X_test_dtm = vect.transform(X_test)

print("Train vector shape : " , X_train_dtm.shape)
print("Test vector shape : ", X_test_dtm.shape)

"""**Logistic Regression model for the Katty Perry data set**"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train_dtm,y_train)

#predicting Label for test data
pred = model.predict(X_test_dtm)
#Checking F1 Score
sklearn.metrics.f1_score(y_test, pred, average='binary')

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
accuracy_score(pred, y_test)

confusion_matrix(y_test, pred)

# The model predicted 64 out of 70 instances correctly
# We had zero false positive and five false negative

X_test[pred > y_test] # zero false positive

X_test[pred < y_test] # 5 false negative

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, model.predict_proba(X_test_dtm)[:, 1])

"""# Explaining predictions using lime"""

#Construct a Pipeline from the given estimators.
from sklearn.pipeline import make_pipeline
#making pipeline using TfidfVectorizer and Logistic Regression model
c = make_pipeline(vect, model)

X_test

print(c.predict_proba([X_test.values[0]]))

#Assigning the class names as spam and not_spam
class_names = ['not_spam','spam']

"""Now we create an explainer object. We pass the ````class_names```` as an argument for prettier display."""

from lime.lime_text import LimeTextExplainer
explainer = LimeTextExplainer(class_names=class_names)

"""We then generate an explanation with at most 10 features for an three arbitrary document in the test set.

**Explaining Instance 1**

Spam Email Correctly Classified
"""

idx = 13 # choose a random single prediction
exp1 = explainer.explain_instance(X_test.values[idx], c.predict_proba, num_features=10)
print('Document id: %d' % idx)
print('Probability(spam) =', c.predict_proba([X_test.values[idx]])[0, 1])
print('Probability(not_spam) =', c.predict_proba([X_test.values[idx]])[0, 0])
print('True class: %s' % y_test.values[idx])

"""The classifier got this example right (it predicted Spam).
The explanation is presented below as a list of weighted features.
"""

exp1.as_list()

"""These weighted features are a linear model, which approximates the behaviour of the Logistic Regression classifier in the vicinity of the test example. Roughly, if we remove 'subscribe' and 'watch' from the content , the prediction should move towards the opposite class (not_spam) by about the sum of the weights for both features. Let's see if this is the case."""

print('Original prediction:', model.predict_proba(X_test_dtm[idx])[0,1])
tmp = X_test_dtm[idx].copy()
tmp[0, vect.vocabulary_['subscribe']] = 0
tmp[0, vect.vocabulary_['watch']] = 0
print('Prediction removing some features:', model.predict_proba(tmp)[0,1])
print('Difference:', model.predict_proba(tmp)[0, 1] - model.predict_proba(X_test_dtm[idx])[0,1])

"""The words that explain the model around this document seem very arbitrary - not much to do with either not_spam or spam. In fact, these are words that appear in the content, which make distinguishing between the classes much easier."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig = exp1.as_pyplot_figure()

"""Finally, we can also include a visualization of the original document, with the words in the explanations highlighted. Notice how the words that affect the classifier the most are all in the content."""

exp1.show_in_notebook(text=True)

"""**Explaining Instance 2**

Non Spam Email Correctly Classified
"""

idx = 20 # choose a random single prediction
exp2 = explainer.explain_instance(X_test.values[idx], c.predict_proba, num_features=10)
print('Document id: %d' % idx)
print('Probability(spam) =', c.predict_proba([X_test.values[idx]])[0, 1])
print('Probability(not_spam) =', c.predict_proba([X_test.values[idx]])[0, 0])
print('True class: %s' % y_test.values[idx])

"""The classifier got this example right (it predicted not_spam).
The explanation is presented below as a list of weighted features.
"""

exp2.as_list()

"""These weighted features are a linear model, which approximates the behaviour of the Logistic Regression classifier in the vicinity of the test example. Roughly, if we remove 'million' and 'video' from the content , the prediction should move towards the opposite class (spam) by about the sum of the weights for both features. Let's see if this is the case."""

print('Original prediction:', model.predict_proba(X_test_dtm[idx])[0, 1])
tmp = X_test_dtm[idx].copy()
tmp[0, vect.vocabulary_['million']] = 0
tmp[0, vect.vocabulary_['video']] = 0
print('Prediction removing some features:', model.predict_proba(tmp)[0,1])
print('Difference:', model.predict_proba(tmp)[0, 1] - model.predict_proba(X_test_dtm[idx])[0,1])

"""The words that explain the model around this document seem very arbitrary - not much to do with either not_spam or spam. In fact, these are words that appear in the content, which make distinguishing between the classes much easier."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig2 = exp2.as_pyplot_figure()

"""
Finally, we can also include a visualization of the original document, with the words in the explanations highlighted. Notice how the words that affect the classifier the most are all in the content."""

exp2.show_in_notebook(text=True)

"""**Explaining Instance 3**

Misclassified Email
"""

idx = 51 # choose a random single prediction
exp3 = explainer.explain_instance(X_test.values[idx], c.predict_proba, num_features=10)
print('Document id: %d' % idx)
print('Probability(spam) =', c.predict_proba([X_test.values[idx]])[0, 1])
print('Probability(not_spam) =', c.predict_proba([X_test.values[idx]])[0, 0])
print('True class: %s' % y_test.values[idx])
exp3.show_in_notebook(text=True)

"""**Understanding why content is wrongly classified**

As we look at the original text (spam email) wrongly classified as (not_spam), it shows that negation is the problem. ‘Katy’, 'perry' and 'love' are the decisive feature that determines the label. However, the email is spam. To improve the performance of our predictive model, we need to take negation into consideration.

The email is categorised as not_spam as it has words like ‘Katy’, 'perry' and 'love'

**Summary**

As you can see in the above examples, LIME-The explainer helps the user understand what's happening behind the black-box model. With the given set of emails(dataset), the Logistic Regression model was able to predict whether it is NOT_SPAM or SPAM, and the LIME explained why. The LIME calculates the weight of the individual words locally in the given data based on the probability and classifies based on the terms that carried the highest weightage. It is evident that if the words with the highest weightage are removed, the prediction probability varies, making a difference to become the other class.
"""